# Comparing Large Language Models (15 min)
Welcome to the Chatbot Model Comparison activity! Here, you will compare the output of three different chatbot models. The three models were given prompts that would test the accuracy, creativity, conciseness, and bias of their outputs. Your job is to select the model that performed best in each category. Let's get started!

Complete the activity [here](https://igfnaqfcyl-13589482-i.codehs.me/index.html).  Then edit this page and write down your reflections here:

### Which model did you find performed best overall, and why?
I personally thought that ChatGPT-4o performed the best overall because it gave the most concise response while providing the perfect amount of information. It wasn't excessive and it was straightforward.

### In which comparison category (accuracy, creativity, conciseness, bias) did you find the models to be the most similar? What about the most different?
I think the models were the most similar in bias because they used really general words that would avoid any bias in the statement. I think the most different was probably the creativity aspect.

### Were you surprised by any of the results?
I was a little bit surprised by how excessive the results were for Llama 3. I thought their responses were way too wordy.

### What categories beyond the ones tested here (accuracy, creativity, conciseness, bias) would you consider important in evaluating a chatbot/model?
I think another important category in evaluating a chatbot is information. The amount of information provided to the user and whether it was enough.
